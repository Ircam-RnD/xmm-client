//import * as gmmUtils from '../utils/gmm-utils';
import * as hhmmUtils from '../utils/hhmm-utils';

/**
 * Hierarchical HMM decoder
 * loads a model trained by the XMM library and processes an input stream of float vectors in real-time
 * if the model was trained for regression, outputs an estimation
 * @class
 */

export default class HhmmDecoder {

  /**
   * @param {number} windowSize - size of the likelihood smoothing window
   */
  constructor(windowSize = 1) {

    /**
     * Size of the likelihood smoothing window
     * @type {number}
     */
    this._likelihoodWindow = windowSize;

    /**
     * The model, as generated by XMM from a training data set
     * @type {Object}
     */
    this.model = undefined;

    /**
     * The model results, containing intermediate results that will be passed to the callback in filter
     * @type {Object}
     */
    this.modelResults = undefined;
  }

  /**
   * @typedef HhmmResults
   * @type {Object}
   * @property {string} likeliest - the likeliest model's label
   * @property {Array.number} likelihoods - the array of all models' normalized likelihoods
   * @property {Array.number} timeProgressions - the array of all models' normalized time progressions
   * @property {Array.Array.number} alphas - the array of all models' states likelihoods array
   * @property {?Array.number} outputValues - if the model was trained with regression, the estimated float vector output
   */

  /**
   * Callback handling estimation results
   * @callback ResultsCallback
   * @param {string} err - description of a potential error
   * @param {HhmmResults} res - object holding the estimation results
   */

  /**
   * The decoding function
   * @param {Array.number} observation - an input float vector to be estimated
   * @param {ResultsCallback} resultsCallback - the callback handling the estimation results
   */
  filter(observation, resultsCallback) {
    if(this.model === undefined) {
      console.log("no model loaded");
      return;
    }

    let err = null;
    let res = null;

    try {
      hhmmUtils.hhmmFilter(observation, this.model, this.modelResults);

      // create results object from relevant modelResults values :

      const lklst = (this.modelResults.likeliest > -1)
                  ? this.model.models[this.modelResults.likeliest].label
                  : 'unknown';
      const lklhds = this.modelResults.smoothed_normalized_likelihoods.slice(0);
      res = {
        likeliest: lklst,
        likelihoods: lklhds,
        alphas: new Array(this.model.models.length)
      }

      for(let i = 0; i < this.model.models.length; i++) {
        if(this.model.configuration.default_parameters.hierarchical) {
          res.alphas[i]
            = this.modelResults.singleClassHmmModelResults[i].alpha_h[0];
        } else {
          res.alphas[i]
            = this.modelResults.singleClassHmmModelResults[i].alpha[0];
        }
      }

      if(this.model.shared_parameters.bimodal) {
        res.outputValues = this.modelResults.output_values.slice(0);
        // results.outputCovariance
        //     = this.modelResults.output_covariance.slice(0);
      }
    } catch (e) {
      err = 'problem occured during filtering : ' + e;
    }
    resultsCallback(err, results);
  }

  /**
   * Resets the intermediate results of the estimation
   */
  reset() {
    /** @todo : write a real reset (see c++ version) */
    this.modelResults.forward_initialized = false;
  }

  // ==================== SETTERS ====================== //

  /**
   * The model generated by XMM
   * It is mandatory for the class to have a model in order to do its job
   * @type {Object}
   */
  set model(model) {      

    this.model = undefined;
    this.modelResults = undefined;

    // test if model is valid here (TODO : write a better test)
    if(model.models !== undefined) {

      //console.log(model);

      this.model = model;
      const m = this.model;
      const nmodels = m.models.length;

      // not used anymore (returns a more complex js object)
      // const nstatesGlobal = m.configuration.default_parameters.states;
      // this.params.frameSize = nstatesGlobal;

      this.modelResults = {
        instant_likelihoods: new Array(nmodels),
        smoothed_log_likelihoods: new Array(nmodels),
        smoothed_likelihoods: new Array(nmodels),
        instant_normalized_likelihoods: new Array(nmodels),
        smoothed_normalized_likelihoods: new Array(nmodels),
        likeliest: -1,
        frontier_v1: new Array(nmodels),
        frontier_v2: new Array(nmodels),
        forward_initialized: false,
        singleClassHmmModelResults: []
      };

      // move output_values / output_covariance here for regression
      // and dupe (.slice(0)) them in sub-modelResults
      const params = m.shared_parameters;
      const dimOut = params.dimension - params.dimension_input;
      this.modelResults.output_values = new Array(dimOut);
      for(let i = 0; i < dimOut; i++) {
        this.modelResults.output_values[i] = 0.0;
      }

      let outCovarSize;
      if(m.configuration.default_parameters.covariance_mode == 0) { // full
        outCovarSize = dimOut * dimOut;
      }
      else { // diagonal
        outCovarSize = dimOut;
      }
      this.modelResults.output_covariance = new Array(outCovarSize);
      for(let i = 0; i < dimOut; i++) {
        this.modelResults.output_covariance[i] = 0.0;
      }

      for(let i = 0; i < nmodels; i++) {

        this.modelResults.instant_likelihoods[i] = 0;
        this.modelResults.smoothed_log_likelihoods[i] = 0;
        this.modelResults.smoothed_likelihoods[i] = 0;
        this.modelResults.instant_normalized_likelihoods[i] = 0;
        this.modelResults.smoothed_normalized_likelihoods[i] = 0;

        const nstates = m.models[i].parameters.states;

        const alpha_h = new Array(3);
        for(let j=0; j<3; j++) {
          alpha_h[j] = new Array(nstates);
          for(let k=0; k<nstates; k++) {
            alpha_h[j][k] = 0;
          }
        }
        
        const alpha = new Array(nstates);
        for(let j = 0; j < nstates; j++) {
          alpha[j] = 0;
        }

        // const winSize = m.shared_parameters.likelihood_window
        // let likelihood_buffer = new Array(winSize);
        let likelihood_buffer = new Array(this._likelihoodWindow);
        for(let j = 0; j < this._likelihoodWindow; j++) {
          likelihood_buffer[j] = 0.0;
        }

        const hmmRes = {
          hierarchical: m.configuration.default_parameters.hierarchical,
          instant_likelihood: 0,
          log_likelihood: 0,
          // for circular buffer implementation
          // (see hmmUpdateResults) :
          likelihood_buffer: likelihood_buffer,
          likelihood_buffer_index: 0,
          progress: 0,

          exit_likelihood: 0,
          exit_ratio: 0,

          likeliest_state: -1,

          // for non-hierarchical :
          previous_alpha: alpha.slice(0),
          alpha: alpha,
          // for hierarchical :       
          alpha_h: alpha_h,
          prior: new Array(nstates),
          transition: new Array(nstates),

          // used in hmmUpdateAlphaWindow
          window_minindex: 0,
          window_maxindex: 0,
          window_normalization_constant: 0,

          // for non-hierarchical mode
          forward_initialized: false,
          
          singleClassGmmModelResults: []  // states
        };

        hmmRes.output_values = this.modelResults.output_values.slice(0);
        hmmRes.output_covariance = this.modelResults.output_covariance.slice(0);

        // add HMM states (GMMs)
        for(let j = 0; j < nstates; j++) {
          const gmmRes = {
            instant_likelihood: 0,
            log_likelihood: 0
          };
          gmmRes.beta = new Array(this.model.models[i].parameters.gaussians);
          for(let k = 0; k < gmmRes.beta.length; k++) {
            gmmRes.beta[k] = 1 / gmmRes.beta.length;
          }
          gmmRes.output_values = hmmRes.output_values.slice(0);
          gmmRes.output_covariance = hmmRes.output_covariance.slice(0);

          hmmRes.singleClassGmmModelResults.push(gmmRes);
        }

        this.modelResults.singleClassHmmModelResults.push(hmmRes);
      }
    }
  }

  set likelihoodWindow(newWindowSize) {
    this._likelihoodWindow = newWindowSize;
    if(this.model === undefined) return;
    const res = this.modelResults.singleClassModelResults;
    for(let i=0; i<this.model.models.length; i++) {
      res[i].likelihood_buffer = new Array(this._likelihoodWindow);
      for(let j=0; j<this._likelihoodWindow; j++) {
        res.likelihood_buffer[j] = 1 / this._likelihoodWindow;
      }
    }
  }

  // ==================== GETTERS ====================== //

  get likeliestLabel() {
    if(this.modelResults !== undefined) {
      if(this.modelResults.likeliest > -1) {
        return this.model.models[this.modelResults.likeliest].label;
      }
    }
    return 'unknown';
    //return('no estimation available');
  }

  get nbClasses() {
    if(this.model !== undefined) {
      return this.model.models.length;
    }
    return 0;
  }

  get model() {
    if(this.model !== undefined) {
      return JSON.fromString(JSON.stringify(this.model));
    }
    return undefined;
  }

  get likelihoodWindow() {
    return this._likelihoodWindow;
  }
}